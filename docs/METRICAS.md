# M√©tricas y Validaci√≥n: TalentMX

## Filosof√≠a Build-Measure-Learn

TalentMX aplica la metodolog√≠a Lean Startup para validar hip√≥tesis con datos reales antes de escalar. Este documento define las m√©tricas clave, hip√≥tesis a validar y experimentos planeados.

---

## Hip√≥tesis Principales

### Hip√≥tesis 1: Velocidad de Conexi√≥n
**Afirmaci√≥n:** El matching con IA reduce en 75% el tiempo de conexi√≥n talento-empresa comparado con m√©todos tradicionales.

- **Baseline industria:** 30 d√≠as promedio (LinkedIn, portales tradicionales)
- **Target TalentMX:** < 7 d√≠as (registro ‚Üí aplicaci√≥n ‚Üí entrevista)
- **M√©trica:** Mediana de d√≠as entre registro y primera entrevista
- **Validaci√≥n:** An√°lisis de cohortes semanales durante primer mes
- **Criterio de √©xito:** > 70% de usuarios logran entrevista en < 10 d√≠as

### Hip√≥tesis 2: Accuracy del Algoritmo
**Afirmaci√≥n:** El matching basado en TF-IDF + competencias genera > 70% de coincidencias relevantes seg√∫n validaci√≥n de empresas.

- **M√©trica:** % de matches marcados como "relevante" por reclutadores
- **Target:** > 70% aprobaci√≥n
- **Validaci√≥n:** Survey post-match + tracking de perfiles visitados
- **Criterio de √©xito:** Empresas contactan al menos 3 de cada 5 matches sugeridos

### Hip√≥tesis 3: Tasa de Conversi√≥n
**Afirmaci√≥n:** Matching inteligente aumenta 40% la tasa de aplicaci√≥n vs. b√∫squeda manual.

- **Baseline manual:** ~30% (usuarios ven oferta y aplican)
- **Target TalentMX:** > 40% conversi√≥n
- **M√©trica:** (Aplicaciones enviadas / Matches mostrados) √ó 100
- **Validaci√≥n:** A/B test (50% matching IA, 50% lista sin ordenar)
- **Criterio de √©xito:** Diferencia estad√≠sticamente significativa (p < 0.05)

---

## M√©tricas AARRR (Pirate Metrics)

### 1. Acquisition (Adquisici√≥n)
**¬øC√≥mo llegan los usuarios?**

- **M√©trica primaria:** Registros nuevos / semana
- **Target MVP:** 50 estudiantes + 10 empresas en primer mes
- **Segmentaci√≥n:** Por sector (semiconductores, automotriz, aerospace)
- **Canales:** Universidad Rosario Castellanos, ferias empleo, LinkedIn, referidos

**KPIs secundarios:**
- Costo por adquisici√≥n (CAC): Target < $5 MXN por estudiante (org√°nico)
- Distribuci√≥n por canal (identificar m√°s efectivo)

### 2. Activation (Activaci√≥n)
**¬øTienen una primera experiencia exitosa?**

- **M√©trica primaria:** % usuarios que completan perfil y ven primer match
- **Target:** > 60% completa perfil en primera sesi√≥n
- **Definici√≥n de "activado":** 
  - Estudiante: Perfil 80%+ completo + ve 3+ matches
  - Empresa: Publica primera oferta + ve 5+ candidatos

**KPIs secundarios:**
- Tiempo promedio para activaci√≥n: Target < 10 minutos
- % que abandona en cada paso del onboarding

### 3. Retention (Retenci√≥n)
**¬øRegresan los usuarios?**

- **M√©trica primaria:** % usuarios activos semana 2
- **Target:** > 40% retenci√≥n semanal (W1 ‚Üí W2)
- **Definici√≥n de "activo":** Login + al menos 1 acci√≥n (ver matches, aplicar, etc.)

**KPIs secundarios:**
- Retenci√≥n por cohorte (semanal, mensual)
- Stickiness ratio: DAU/MAU (Target > 0.2)
- Razones de abandono (encuesta exit)

### 4. Referral (Referencias)
**¬øRecomiendan la plataforma?**

- **M√©trica primaria:** % usuarios que invitan compa√±eros
- **Target:** > 20% comparte plataforma
- **Mecanismo:** Bot√≥n "Invitar compa√±ero" con tracking de referidos

**KPIs secundarios:**
- Viral coefficient (K): Target > 0.5 en mes 3
- NPS (Net Promoter Score): Target > 50

### 5. Revenue (Ingresos)
**¬øEst√°n dispuestos a pagar?**

- **M√©trica primaria:** % empresas que pagan por premium (post-MVP)
- **Target:** > 15% conversi√≥n a pago en mes 3
- **Modelo freemium:** 
  - Gratis: 3 ofertas publicadas, 10 matches/mes
  - Premium: Ofertas ilimitadas, contacto directo, analytics

**KPIs secundarios:**
- Lifetime Value (LTV): Target > $500 MXN/empresa
- LTV:CAC ratio: Target > 3:1

---

## Dashboard de M√©tricas en Tiempo Real

### M√©tricas Visibles en UI (para jueces/inversionistas)

**Panel principal muestra:**
1. **Total matches generados** (acumulado desde inicio)
2. **Estudiantes activos** (√∫nicos que han usado matching)
3. **Promedio matches por estudiante** (se√±al de calidad de algoritmo)
4. **Tasa de aplicaci√≥n** (aplicaciones / matches √ó 100)
5. **Sectores m√°s demandados** (gr√°fico de barras)

**Actualizaci√≥n:** Tiempo real (cada action de usuario)

---

## Experimentos A/B Planeados

### Experimento 1: Ordenamiento de Matches
**Pregunta:** ¬øEl ordenamiento por score de compatibilidad afecta la tasa de aplicaci√≥n?

- **Grupo A (Control):** Matches ordenados aleatoriamente
- **Grupo B (Tratamiento):** Matches ordenados por score descendente
- **Duraci√≥n:** 2 semanas
- **M√©trica:** Tasa de aplicaci√≥n por grupo
- **Hip√≥tesis:** Grupo B tendr√° > 30% m√°s aplicaciones

### Experimento 2: Umbral de Compatibilidad
**Pregunta:** ¬øQu√© umbral m√≠nimo de score maximiza relevancia sin reducir volumen?

- **Variantes:** 30%, 40%, 50%, 60%
- **Duraci√≥n:** 1 semana por umbral
- **M√©tricas:** 
  - Cantidad de matches generados
  - % de matches contactados por empresas
- **Hip√≥tesis:** 50% es el sweet spot

### Experimento 3: Notificaciones
**Pregunta:** ¬øLas notificaciones de nuevos matches aumentan la retenci√≥n?

- **Grupo A:** Sin notificaciones email
- **Grupo B:** Email diario con nuevos matches
- **Grupo C:** Email solo si > 70% compatibilidad
- **M√©trica:** Retenci√≥n D7 (day 7)
- **Hip√≥tesis:** Grupo C tendr√° mayor retenci√≥n sin aumentar churn

---

## Implementaci√≥n T√©cnica

### Backend: Event Tracking

```python
# Eventos trackeados autom√°ticamente:
- "user_registered" (tipo: estudiante/empresa)
- "profile_completed" (% completitud)
- "match_generated" (student_id, offer_id, score)
- "match_viewed" (quien vio el perfil)
- "application_sent" (student_id, offer_id)
- "application_viewed" (empresa ve aplicaci√≥n)
- "interview_scheduled" (conversi√≥n final)
```

### Frontend: Analytics Dashboard

**Ubicaci√≥n:** Tab "M√©tricas" en dashboard principal (`frontend/app.js`)

**Visualizaciones:**
1. Funnel chart: Registros ‚Üí Activados ‚Üí Matches ‚Üí Aplicaciones ‚Üí Entrevistas
2. Time-series: Usuarios activos (7 d√≠as, 30 d√≠as)
3. Heatmap: Compatibilidad por sector
4. Top 10: Competencias m√°s demandadas

---

## Criterios de Decisi√≥n (Build-Measure-Learn)

### Pivot si:
- Retenci√≥n W2 < 20% despu√©s de 3 iteraciones
- Accuracy del algoritmo < 50% (m√°s bajo que random)
- CAC > LTV (econom√≠a de unidad negativa)

### Perseverar si:
- Al menos 2 de 3 hip√≥tesis principales validadas
- Retenci√≥n W2 > 30%
- Feedback cualitativo positivo (NPS > 40)

### Acelerar si:
- Las 3 hip√≥tesis validadas
- Retenci√≥n W2 > 50%
- K (viral coefficient) > 0.7
- Demanda org√°nica supera capacidad

---

## Roadmap de Validaci√≥n

### Semana 1-2: MVP T√©cnico (ACTUAL)
- ‚úÖ API funcional con algoritmo matching
- ‚úÖ Dashboard b√°sico
- üîÑ Sistema de tracking implementado
- üîÑ Documentaci√≥n de m√©tricas

### Semana 3-4: Validaci√≥n con Early Adopters
- [ ] Onboarding de 20 estudiantes Universidad Rosario Castellanos
- [ ] Onboarding de 3-5 empresas piloto (1 por sector)
- [ ] Recolecci√≥n de feedback cualitativo (entrevistas 1-a-1)
- [ ] Ajustes de algoritmo basados en feedback

### Mes 2: Iteraci√≥n y Optimizaci√≥n
- [ ] Implementar top 3 features solicitadas
- [ ] Ejecutar experimentos A/B
- [ ] Validar hip√≥tesis 1 y 2
- [ ] Documentar learnings en formato "What we learned"

### Mes 3: Preparaci√≥n para Escala
- [ ] Base de datos PostgreSQL (reemplazar in-memory)
- [ ] Autenticaci√≥n robusta (JWT)
- [ ] Infraestructura AWS (auto-scaling)
- [ ] Alcanzar m√©tricas target para pitch a inversionistas

---

## Reportes y Transparencia

### Reportes Semanales (Formato Lean Canvas)
1. **Qu√© construimos:** Features implementadas esta semana
2. **Qu√© medimos:** Datos de las m√©tricas AARRR
3. **Qu√© aprendimos:** Insights inesperados, cambios en hip√≥tesis
4. **Pr√≥ximos experimentos:** Qu√© vamos a probar la siguiente semana

### P√∫blico
- Equipo interno: Reporte semanal completo
- Mentores/Inversionistas: Reporte mensual ejecutivo
- Usuarios: Changelog p√∫blico con mejoras basadas en feedback

---

## Contacto y Feedback

Para reportar m√©tricas inesperadas o sugerir nuevos experimentos:
- Email: henry@talentmx.com
- GitHub Issues: HenrySpark369/Tlamatini

**√öltima actualizaci√≥n:** Diciembre 8, 2025  
**Pr√≥xima revisi√≥n:** Diciembre 15, 2025 (post-onboarding early adopters)
